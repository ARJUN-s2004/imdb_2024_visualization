{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collectin code from imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# # Set up Selenium WebDriver\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "# # IMDb 2024 Movies URL (Page 1)\n",
    "\n",
    "# base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=action&count=250\"\n",
    "\n",
    "# # Initialize list to store data\n",
    "# data = []\n",
    "\n",
    "# # Loop through all pages\n",
    "# page_num = 1\n",
    "# while True:\n",
    "#     print(f\"Scraping Page {page_num}...\")\n",
    "\n",
    "#     driver.get(base_url)\n",
    "#     time.sleep(5)  # Wait for page to load\n",
    "\n",
    "#     # Scroll down slowly to load all content\n",
    "#     for _ in range(5):  \n",
    "#         driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "#         time.sleep(5)\n",
    "\n",
    "#     # Collecting data\n",
    "#     titles = driver.find_elements(By.XPATH, \"//h3[@class='ipc-title__text']\")\n",
    "#     ratings = driver.find_elements(By.XPATH, \"//span[@class='ipc-rating-star--rating']\")\n",
    "#     votes = driver.find_elements(By.XPATH, \"//span[@class='ipc-rating-star--voteCount']\")\n",
    "#     durations = driver.find_elements(By.XPATH, \"//div[contains(@class, 'dli-title-metadata')]/span[contains(@class, 'dli-title-metadata-item')][2]\")\n",
    "\n",
    "#     # Storing data\n",
    "#     for i in range(len(titles)):\n",
    "#         try:\n",
    "#             title = titles[i].text\n",
    "#             rating = ratings[i].text if i < len(ratings) else 'N/A'\n",
    "#             vote = votes[i].text if i < len(votes) else 'N/A'\n",
    "#             duration = durations[i].text if i < len(durations) else 'N/A'\n",
    "#             genre = \"action\"\n",
    "#             data.append({'Title': title, 'Rating': rating, 'Votes': vote, 'Duration': duration, 'Genre': genre})\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error at index {i}: {e}\")\n",
    "\n",
    "#     # Check if \"Next\" button exists\n",
    "#     try:\n",
    "#         next_button = driver.find_element(By.XPATH, \"//a[contains(@class, 'lister-page-next')]\")\n",
    "#         base_url = next_button.get_attribute(\"href\")  # Get next page URL\n",
    "#         page_num += 1\n",
    "#     except:\n",
    "#         print(\"No more pages found. Scraping completed.\")\n",
    "#         break\n",
    "\n",
    "# # Save data to CSV\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv(f\"{genre}_data.csv\", index=False)\n",
    "\n",
    "# print(f\"✅ Scraping Completed. Data saved as {genre}_data.csv\")\n",
    "\n",
    "# # Keep the browser open for review\n",
    "# input(\"Press ENTER to close the browser...\")\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1...\n",
      "No more pages found. Scraping completed.\n",
      "✅ Scraping Completed. Data saved as western_data.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# IMDb 2024 Movies URL (Page 1)\n",
    "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=western&count=250\"\n",
    "\n",
    "data = []  # Initialize list to store data\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"Scraping Page {page_num}...\")\n",
    "    driver.get(base_url)\n",
    "    time.sleep(5)  # Wait for page to load\n",
    "\n",
    "    # Scroll down slowly to load all content\n",
    "    for _ in range(5):  \n",
    "        driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Collecting data\n",
    "    titles = driver.find_elements(By.XPATH, \"//h3[@class='ipc-title__text']\")\n",
    "    ratings = driver.find_elements(By.XPATH, \"//span[@class='ipc-rating-star--rating']\")\n",
    "    votes = driver.find_elements(By.XPATH, \"//span[@class='ipc-rating-star--voteCount']\")\n",
    "    durations = driver.find_elements(By.XPATH, \"//div[contains(@class, 'dli-title-metadata')]/span[contains(@class, 'dli-title-metadata-item')][2]\")\n",
    "\n",
    "    # Storing data\n",
    "    for i in range(len(titles)):\n",
    "        try:\n",
    "            title = titles[i].text if i < len(titles) else None\n",
    "            rating = ratings[i].text if i < len(ratings) else None\n",
    "            vote = votes[i].text if i < len(votes) else None\n",
    "            duration = durations[i].text if i < len(durations) else None\n",
    "            genre = \"western\"\n",
    "            \n",
    "            # Skip rows with missing data\n",
    "            if None in (title, rating, vote, duration):\n",
    "                continue\n",
    "            \n",
    "            data.append({'Title': title, 'Rating': rating, 'Votes': vote, 'Duration': duration, 'Genre': genre})\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {i}: {e}\")\n",
    "\n",
    "    # Check if \"Next\" button exists\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[contains(@class, 'lister-page-next')]\")\n",
    "        base_url = next_button.get_attribute(\"href\")  # Get next page URL\n",
    "        page_num += 1\n",
    "    except:\n",
    "        print(\"No more pages found. Scraping completed.\")\n",
    "        break\n",
    "\n",
    "# Save data to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"{genre}_data.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Scraping Completed. Data saved as {genre}_data.csv\")\n",
    "\n",
    "\n",
    "# Keep the browser open for review\n",
    "input(\"Press ENTER to close the browser...\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combaining multiple data sets scraped from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\imdb_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine multiple CSV files into a single CSV file using Python and Pandas\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of file paths with raw strings\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\action_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\adventure_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\animation_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\biography_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\comedy_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\crime_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\documentary_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\drama_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\family_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\fantasy_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\history_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\horror_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\music_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\musical_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\mystery_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\news_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\romance_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\sci-fi_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\sport_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\thriller_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\war_data.csv\",\n",
    "    r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\western_data.csv\"\n",
    "]\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each file path and append the data\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "output_path = r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\imdb_2024.csv\"\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Horizon: An American Saga - Chapter 1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>(39K)</td>\n",
       "      <td>3h 1m</td>\n",
       "      <td>western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Rust</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(165)</td>\n",
       "      <td>2h 13m</td>\n",
       "      <td>western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Horizon: An American Saga - Chapter 2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>(1.2K)</td>\n",
       "      <td>3h 10m</td>\n",
       "      <td>western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. The Thicket</td>\n",
       "      <td>5.8</td>\n",
       "      <td>(2.9K)</td>\n",
       "      <td>1h 48m</td>\n",
       "      <td>western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The Unholy Trinity</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(49)</td>\n",
       "      <td>1h 33m</td>\n",
       "      <td>western</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Rating    Votes Duration    Genre\n",
       "0  1. Horizon: An American Saga - Chapter 1     6.7    (39K)    3h 1m  western\n",
       "1                                   2. Rust     6.0    (165)   2h 13m  western\n",
       "2  3. Horizon: An American Saga - Chapter 2     7.1   (1.2K)   3h 10m  western\n",
       "3                            4. The Thicket     5.8   (2.9K)   1h 48m  western\n",
       "4                     5. The Unholy Trinity     7.9     (49)   1h 33m  western"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11522, 5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv(r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi project 1\\imdb_2024.csv\")\n",
    "\n",
    "db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the scraped data and handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed. Cleaned dataset saved to imdb_2024_fully_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Arjun\\OneDrive\\Desktop\\guvi\\imdb_2024.csv\")\n",
    "\n",
    "# Remove ranking numbers from Title (e.g., \"1. Dune: Part Two\" -> \"Dune: Part Two\")\n",
    "df[\"Title\"] = df[\"Title\"].str.replace(r\"^\\d+\\.\\s*\", \"\", regex=True)\n",
    "\n",
    "# Convert Votes to numeric values (e.g., \"(610K)\" -> 610000)\n",
    "def convert_votes(v):\n",
    "    if isinstance(v, str):\n",
    "        v = v.replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")  # Remove parentheses and commas\n",
    "        if \"K\" in v:\n",
    "            return int(float(v.replace(\"K\", \"\")) * 1000)\n",
    "        elif \"M\" in v:\n",
    "            return int(float(v.replace(\"M\", \"\")) * 1000000)\n",
    "        else:\n",
    "            return int(float(v))\n",
    "    return pd.NA\n",
    "\n",
    "df[\"Votes\"] = df[\"Votes\"].apply(convert_votes)\n",
    "\n",
    "# Convert Duration from \"xh ym\" to total minutes (e.g., \"2h 30m\" -> 150)\n",
    "def convert_duration(d):\n",
    "    if isinstance(d, str):\n",
    "        h, m = 0, 0\n",
    "        match = re.match(r\"(?:(\\d+)h)?\\s*(?:(\\d+)m)?\", d)\n",
    "        if match:\n",
    "            h = int(match.group(1)) if match.group(1) else 0\n",
    "            m = int(match.group(2)) if match.group(2) else 0\n",
    "        return h * 60 + m\n",
    "    return pd.NA\n",
    "\n",
    "df[\"Duration\"] = df[\"Duration\"].apply(convert_duration)\n",
    "\n",
    "# Drop rows where Rating is NaN\n",
    "# df = df.dropna(subset=[\"Rating\"])\n",
    "# df = df.dropna(subset=[\"Votes\"])\n",
    "# df = df.dropna(subset=[\"Duration\"])\n",
    "\n",
    "# # Handle missing values using median\n",
    "# df[\"Votes\"] = df[\"Votes\"].fillna(df[\"Votes\"].median())\n",
    "df[\"Duration\"] = df[\"Duration\"].fillna(df[\"Duration\"].median())\n",
    "\n",
    "# Droping duplicate values\n",
    "df = df.drop_duplicates(subset=[\"Title\",'Genre'], keep=\"first\")\n",
    "\n",
    "# Save the fully cleaned dataset\n",
    "final_cleaned_file_path = \"imdb_2024_cleaned.csv\"\n",
    "df.to_csv(final_cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Data cleaning completed. Cleaned dataset saved to imdb_2024_fully_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title       0\n",
       "Rating      0\n",
       "Votes       0\n",
       "Duration    0\n",
       "Genre       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11496, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
